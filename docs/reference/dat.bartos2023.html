<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><!-- Inform modern browsers that this page supports both dark and light color schemes,
  and the page author prefers light. --><meta name="color-scheme" content="dark light"><script>
  // If `prefers-color-scheme` is not supported, fall back to light mode.
  // i.e. In this case, inject the `light` CSS before the others, with
  // no media filter so that it will be downloaded with highest priority.
  if (window.matchMedia("(prefers-color-scheme: dark)").media === "not all") {
    document.documentElement.style.display = "none";
    document.head.insertAdjacentHTML(
      "beforeend",
      "<link id=\"css\" rel=\"stylesheet\" href=\"https://bootswatch.com/3/flatly/bootstrap.css\" onload=\"document.documentElement.style.display = ''\">"
    );
  }
</script><title>Results of 350,757 Coin Flips to Examine Same-Side Bias — dat.bartos2023 • metadat</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous"><link href="../docsearch.css" rel="stylesheet"><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Results of 350,757 Coin Flips to Examine Same-Side Bias — dat.bartos2023"><meta property="og:description" content="Results from 350,757 coin flips by 48 people to examine the presence of same-side bias."><meta name="twitter:card" content="summary_large_image"><meta name="twitter:creator" content="@wviechtb"><meta name="twitter:site" content="@wviechtb"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Flatly Theme - Light  --><link id="css-light" rel="stylesheet" href="https://bootswatch.com/3/flatly/bootstrap.css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><!-- Darkly Theme - Dark --><link id="css-dark" rel="stylesheet" href="https://bootswatch.com/3/darkly/bootstrap.css" media="(prefers-color-scheme: dark)"><!-- preferably CSS --><link rel="stylesheet" href="../preferably.css"><link id="css-code-light" rel="stylesheet" href="../code-color-scheme-light.css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link id="css-code-dark" rel="stylesheet" href="../code-color-scheme-dark.css" media="(prefers-color-scheme: dark)"><script src="../darkswitch.js"></script></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">metadat</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.3-0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Datasets / Functions</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
          <a href="#" id="css-toggle-btn">
            <span class="fas fa-adjust fa-lg"></span>
          </a>
        </li>
        
        <li>
  <a href="https://scholar.social/@wviechtb" class="external-link">Mastodon</a>
</li>
<li>
  <a href="https://github.com/wviechtb/metadat" class="external-link">GitHub</a>
</li>
        
        


      </ul><form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off"></div>
      </form>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Results of 350,757 Coin Flips to Examine Same-Side Bias</h1>
    
    <div class="hidden name"><code>dat.bartos2023.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Results from 350,757 coin flips by 48 people to examine the presence of same-side bias.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="va">dat.bartos2023</span></span></code></pre></div>
    </div>

    <div id="format">
    <h2>Format</h2>
    <p>The data frame contains the following columns:</p><table class="table table"><tr><td><b>person</b></td><td><code>character</code></td><td>person identifier</td></tr><tr><td><b>hsame</b></td><td><code>numeric</code></td><td>number of flips where the coin landed on heads and on the same side as where it started</td></tr><tr><td><b>hdiff</b></td><td><code>numeric</code></td><td>number of flips where the coin landed on heads and on the different side as where it started</td></tr><tr><td><b>tsame</b></td><td><code>numeric</code></td><td>number of flips where the coin landed on tails and on the same side as where it started</td></tr><tr><td><b>tdiff</b></td><td><code>numeric</code></td><td>number of flips where the coin landed on tails and on the different side as where it started</td></tr><tr><td><b>same</b></td><td><code>numeric</code></td><td>number of flips where the coin landed on the same side as where it started</td></tr><tr><td><b>flips</b></td><td><code>numeric</code></td><td>total number of flips</td></tr></table></div>
    <div id="details">
    <h2>Details</h2>
    <p>In a landmark study by Bartoš et al. (2023), 48 people flipped a coin (of various currencies and/or denominations) a total of 350,757 times, recording on each flip whether it landed on heads or tails and whether the coin landed on the same side as where it started or on the different side. The goal of this experiment was to examine the model by Diaconis, Holmes, and Montgomery (2007), according to which flipped coins have a slightly higher than 50% chance (of around 51% according to the D-H-M model) of landing on the same side as where they started.</p>
    </div>
    <div id="source">
    <h2>Source</h2>
    <p>Bartoš, F., Sarafoglou, A., Godmann, H. R., Sahrani, A., Leunk, D. K., Gui, P. Y., Voss, D., Ullah, K., Zoubek, M. J., Nippold, F., Aust, F., Vieira, F. F., Islam, C.-G., Zoubek, A. J., Shabani, S., Petter, J., Roos, I. B., Finnemann, A., Lob, A. B., Hoffstadt, M. F., Nak, J., de Ron, J., Derks, K., Huth, K., Terpstra, S., Bastelica, T., Matetovici, M., Ott, V. L., Zetea, A. S., Karnbach, K., Donzallaz, M. C., John, A., Moore, R. M., Assion, F., van Bork, R., Leidinger, T. E., Zhao, X., Motaghi, A. K., Pan, T., Armstrong, H., Peng, T., Bialas, M., Pang, J. Y.-C., Fu, B., Yang, S., Lin, X., Sleiffer, D., Bognar, M., Aczel, B., &amp; Wagenmakers, E.-J. (2023). Fair coins tend to land on the same side they started: Evidence from 350,757 flips. <em>arXiv</em>, 2310.04153, v2. <a href="https://arxiv.org/abs/2310.04153" class="external-link">https://arxiv.org/abs/2310.04153</a></p>
    </div>
    <div id="references">
    <h2>References</h2>
    <p>Diaconis, P., Holmes, S., &amp; Montgomery, R. (2007). Dynamical bias in the coin toss. <em>SIAM Review</em>, <b>49</b>(2), 211-235. <a href="https://doi.org/10.1137/s0036144504446436" class="external-link">https://doi.org/10.1137/s0036144504446436</a></p>
    </div>
    <div id="author">
    <h2>Author</h2>
    <p>Wolfgang Viechtbauer, <a href="mailto:wvb@metafor-project.org">wvb@metafor-project.org</a>, <a href="https://www.metafor-project.org" class="external-link">https://www.metafor-project.org</a></p>
    </div>
    <div id="concepts">
    <h2>Concepts</h2>
    <p>physics, human factors, proportions, multivariate models</p>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co">### copy data into 'dat' and examine data</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="va">dat.bartos2023</span></span></span>
<span class="r-in"><span><span class="va">dat</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        person hsame hdiff tsame tdiff  same flips</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1     XiaoyiL   375   406   405   414   780  1600</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 2    JoyceYCP   588   586   538   588  1126  2300</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 3   AndreeaSZ  1129  1134  1075  1139  2204  4477</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 4     KaleemU  3506  3642  3550  3626  7056 14324</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 5    FelipeFV  2502  2531  2455  2527  4957 10015</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 6       ArneJ   995   982   942   981  1937  3900</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 7       AmirS  3756  3775  3702  3779  7458 15012</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 8     ChrisGI  2546  2519  2425  2515  4971 10005</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 9   FrederikA  2564  2638  2655  2643  5219 10500</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 10 FranziskaN  2634  2718  2734  2671  5368 10757</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 11   RietvanB   876   899   925   900  1801  3600</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 12     JasonN  1692  1676  1660  1672  3352  6700</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 13   PierreYG  3825  3745  3681  3749  7506 15000</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 14  KarolineH  1370  1369  1391  1370  2761  5500</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 15    SjoerdT  1291  1247  1219  1243  2510  5000</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 16      SaraS  2615  2486  2407  2492  5022 10000</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 17   HenrikRG  4382  4264  4267  4269  8649 17182</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 18      IrmaT   188   173   165   175   353   701</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 19 KatharinaK  1136  1088  1084  1092  2220  4400</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 20      JillR  1619  1601  1642  1601  3261  6463</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 21 FrantisekB  5097  4979  5051  4973 10148 20100</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 22 IngeborgBR  2132  2126  2208  2130  4340  8596</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 23  VincentLO  1143  1215  1332  1210  2475  4900</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 24     EricJW  1012  1015  1059  1014  2071  4100</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 25     MalteZ  2831  2715  2728  2726  5559 11000</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 26  TheresaEL   895   866   874   865  1769  3500</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 27     DavidV  3552  3933  4034  3480  7586 14999</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 28    AntonJZ  2587  2463  2482  2472  5069 10004</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 29     MagdaM  1244  1221  1266  1213  2510  4944</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 30    ThomasB  1221  1233  1319  1227  2540  5000</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 31     BohanF   580   544   538   538  1118  2200</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 32     JonasP  2546  2458  2534  2458  5080  9996</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 33    HannahA   704   739   821   736  1525  3000</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 34   AdrianKM   880   828   869   823  1749  3400</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 35    AaronBL  1937  1787  1878  1798  3815  7400</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 36      KoenD  1622  1550  1687  1541  3309  6400</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 37 MichelleCD  1118  1037  1106  1039  2224  4300</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 38      RoyMM   971   942  1049   938  2020  3900</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 39      TingP   855   770   803   772  1658  3200</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 40      MaraB   728   660   698   664  1426  2750</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 41      AdamF  2175  1996  2159  1998  4334  8328</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 42 AlexandraS  4556  4180  4524  4174  9080 17434</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 43   MadlenFH  1769  1699  1936  1694  3705  7098</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 44    DavidKL  3903  3552  3992  3553  7895 15000</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 45 XiaochangZ   901   804   968   808  1869  3481</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 46 FranziskaA   990   876  1065   869  2055  3800</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 47       JanY   510   368   446   367   956  1691</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 48    TianqiP   780   557   902   561  1682  2800</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### load metafor package</span></span></span>
<span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://www.metafor-project.org" class="external-link">metafor</a></span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### compute proportions and the corresponding sampling variances</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/escalc.html" class="external-link">escalc</a></span><span class="op">(</span>measure<span class="op">=</span><span class="st">"PR"</span>, xi<span class="op">=</span><span class="va">same</span>, ni<span class="op">=</span><span class="va">flips</span>, data<span class="op">=</span><span class="va">dat</span>, slab<span class="op">=</span><span class="va">person</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">dat</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        person hsame hdiff tsame tdiff  same flips     yi     vi </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1     XiaoyiL   375   406   405   414   780  1600 0.4875 0.0002 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 2    JoyceYCP   588   586   538   588  1126  2300 0.4896 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 3   AndreeaSZ  1129  1134  1075  1139  2204  4477 0.4923 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 4     KaleemU  3506  3642  3550  3626  7056 14324 0.4926 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 5    FelipeFV  2502  2531  2455  2527  4957 10015 0.4950 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 6       ArneJ   995   982   942   981  1937  3900 0.4967 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 7       AmirS  3756  3775  3702  3779  7458 15012 0.4968 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 8     ChrisGI  2546  2519  2425  2515  4971 10005 0.4969 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 9   FrederikA  2564  2638  2655  2643  5219 10500 0.4970 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 10 FranziskaN  2634  2718  2734  2671  5368 10757 0.4990 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 11   RietvanB   876   899   925   900  1801  3600 0.5003 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 12     JasonN  1692  1676  1660  1672  3352  6700 0.5003 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 13   PierreYG  3825  3745  3681  3749  7506 15000 0.5004 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 14  KarolineH  1370  1369  1391  1370  2761  5500 0.5020 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 15    SjoerdT  1291  1247  1219  1243  2510  5000 0.5020 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 16      SaraS  2615  2486  2407  2492  5022 10000 0.5022 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 17   HenrikRG  4382  4264  4267  4269  8649 17182 0.5034 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 18      IrmaT   188   173   165   175   353   701 0.5036 0.0004 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 19 KatharinaK  1136  1088  1084  1092  2220  4400 0.5045 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 20      JillR  1619  1601  1642  1601  3261  6463 0.5046 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 21 FrantisekB  5097  4979  5051  4973 10148 20100 0.5049 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 22 IngeborgBR  2132  2126  2208  2130  4340  8596 0.5049 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 23  VincentLO  1143  1215  1332  1210  2475  4900 0.5051 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 24     EricJW  1012  1015  1059  1014  2071  4100 0.5051 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 25     MalteZ  2831  2715  2728  2726  5559 11000 0.5054 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 26  TheresaEL   895   866   874   865  1769  3500 0.5054 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 27     DavidV  3552  3933  4034  3480  7586 14999 0.5058 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 28    AntonJZ  2587  2463  2482  2472  5069 10004 0.5067 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 29     MagdaM  1244  1221  1266  1213  2510  4944 0.5077 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 30    ThomasB  1221  1233  1319  1227  2540  5000 0.5080 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 31     BohanF   580   544   538   538  1118  2200 0.5082 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 32     JonasP  2546  2458  2534  2458  5080  9996 0.5082 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 33    HannahA   704   739   821   736  1525  3000 0.5083 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 34   AdrianKM   880   828   869   823  1749  3400 0.5144 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 35    AaronBL  1937  1787  1878  1798  3815  7400 0.5155 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 36      KoenD  1622  1550  1687  1541  3309  6400 0.5170 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 37 MichelleCD  1118  1037  1106  1039  2224  4300 0.5172 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 38      RoyMM   971   942  1049   938  2020  3900 0.5179 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 39      TingP   855   770   803   772  1658  3200 0.5181 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 40      MaraB   728   660   698   664  1426  2750 0.5185 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 41      AdamF  2175  1996  2159  1998  4334  8328 0.5204 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 42 AlexandraS  4556  4180  4524  4174  9080 17434 0.5208 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 43   MadlenFH  1769  1699  1936  1694  3705  7098 0.5220 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 44    DavidKL  3903  3552  3992  3553  7895 15000 0.5263 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 45 XiaochangZ   901   804   968   808  1869  3481 0.5369 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 46 FranziskaA   990   876  1065   869  2055  3800 0.5408 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 47       JanY   510   368   446   367   956  1691 0.5653 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 48    TianqiP   780   557   902   561  1682  2800 0.6007 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### compute confidence intervals for the individual proportions (as in Table 1)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">dat</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">6</span><span class="op">:</span><span class="fl">8</span>,<span class="fl">13</span>,<span class="fl">14</span><span class="op">)</span><span class="op">]</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        person  same flips    yi ci.lb ci.ub </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1     XiaoyiL   780  1600 0.487 0.463 0.512 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 2    JoyceYCP  1126  2300 0.490 0.469 0.510 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 3   AndreeaSZ  2204  4477 0.492 0.478 0.507 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 4     KaleemU  7056 14324 0.493 0.484 0.501 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 5    FelipeFV  4957 10015 0.495 0.485 0.505 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 6       ArneJ  1937  3900 0.497 0.481 0.512 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 7       AmirS  7458 15012 0.497 0.489 0.505 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 8     ChrisGI  4971 10005 0.497 0.487 0.507 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 9   FrederikA  5219 10500 0.497 0.487 0.507 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 10 FranziskaN  5368 10757 0.499 0.490 0.508 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 11   RietvanB  1801  3600 0.500 0.484 0.517 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 12     JasonN  3352  6700 0.500 0.488 0.512 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 13   PierreYG  7506 15000 0.500 0.492 0.508 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 14  KarolineH  2761  5500 0.502 0.489 0.515 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 15    SjoerdT  2510  5000 0.502 0.488 0.516 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 16      SaraS  5022 10000 0.502 0.492 0.512 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 17   HenrikRG  8649 17182 0.503 0.496 0.511 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 18      IrmaT   353   701 0.504 0.467 0.541 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 19 KatharinaK  2220  4400 0.505 0.490 0.519 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 20      JillR  3261  6463 0.505 0.492 0.517 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 21 FrantisekB 10148 20100 0.505 0.498 0.512 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 22 IngeborgBR  4340  8596 0.505 0.494 0.515 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 23  VincentLO  2475  4900 0.505 0.491 0.519 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 24     EricJW  2071  4100 0.505 0.490 0.520 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 25     MalteZ  5559 11000 0.505 0.496 0.515 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 26  TheresaEL  1769  3500 0.505 0.489 0.522 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 27     DavidV  7586 14999 0.506 0.498 0.514 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 28    AntonJZ  5069 10004 0.507 0.497 0.516 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 29     MagdaM  2510  4944 0.508 0.494 0.522 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 30    ThomasB  2540  5000 0.508 0.494 0.522 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 31     BohanF  1118  2200 0.508 0.487 0.529 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 32     JonasP  5080  9996 0.508 0.498 0.518 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 33    HannahA  1525  3000 0.508 0.490 0.526 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 34   AdrianKM  1749  3400 0.514 0.498 0.531 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 35    AaronBL  3815  7400 0.516 0.504 0.527 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 36      KoenD  3309  6400 0.517 0.505 0.529 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 37 MichelleCD  2224  4300 0.517 0.502 0.532 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 38      RoyMM  2020  3900 0.518 0.502 0.534 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 39      TingP  1658  3200 0.518 0.501 0.535 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 40      MaraB  1426  2750 0.519 0.500 0.537 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 41      AdamF  4334  8328 0.520 0.510 0.531 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 42 AlexandraS  9080 17434 0.521 0.513 0.528 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 43   MadlenFH  3705  7098 0.522 0.510 0.534 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 44    DavidKL  7895 15000 0.526 0.518 0.534 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 45 XiaochangZ  1869  3481 0.537 0.520 0.553 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 46 FranziskaA  2055  3800 0.541 0.525 0.557 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 47       JanY   956  1691 0.565 0.542 0.589 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 48    TianqiP  1682  2800 0.601 0.583 0.619 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### compute a confidence interval based on the column totals</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="fu"><a href="https://wviechtb.github.io/metafor/reference/escalc.html" class="external-link">escalc</a></span><span class="op">(</span>measure<span class="op">=</span><span class="st">"PR"</span>, xi<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">same</span><span class="op">)</span>, ni<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">flips</span><span class="op">)</span><span class="op">)</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>      yi    vi   sei      zi  pval ci.lb ci.ub </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1 0.508 0.000 0.001 601.435 &lt;.001 0.506 0.509 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### this is the same as meta-analyzing the proportions directly using an equal-effects</span></span></span>
<span class="r-in"><span><span class="co">### model and also computing the sampling variances under the assumption that the true</span></span></span>
<span class="r-in"><span><span class="co">### proportions are homogeneous</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span>measure<span class="op">=</span><span class="st">"PR"</span>, xi<span class="op">=</span><span class="va">same</span>, ni<span class="op">=</span><span class="va">flips</span>, vtype<span class="op">=</span><span class="st">"AV"</span>, method<span class="op">=</span><span class="st">"EE"</span>, data<span class="op">=</span><span class="va">dat</span>, digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Equal-Effects Model (k = 48)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I^2 (total heterogeneity / total variability):   82.28%</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> H^2 (total variability / sampling variability):  5.64</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Test for Heterogeneity:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Q(df = 47) = 265.264, p-val &lt; .001</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Model Results:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> estimate     se     zval   pval  ci.lb  ci.ub      </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    0.508  0.001  601.435  &lt;.001  0.506  0.509  *** </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ---</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### fit a random-effects model</span></span></span>
<span class="r-in"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span><span class="va">yi</span>, <span class="va">vi</span>, data<span class="op">=</span><span class="va">dat</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Random-Effects Model (k = 48; tau^2 estimator: REML)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau^2 (estimated amount of total heterogeneity): 0.0003 (SE = 0.0001)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau (square root of estimated tau^2 value):      0.0160</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I^2 (total heterogeneity / total variability):   88.10%</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> H^2 (total variability / sampling variability):  8.40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Test for Heterogeneity:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Q(df = 47) = 269.9833, p-val &lt; .0001</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Model Results:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> estimate      se      zval    pval   ci.lb   ci.ub      </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.5100  0.0025  201.9923  &lt;.0001  0.5050  0.5149  *** </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ---</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### profile likelihood confidence interval for tau^2</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">res</span>, type<span class="op">=</span><span class="st">"PL"</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        estimate   ci.lb   ci.ub </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau^2    0.0003  0.0002  0.0005 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau      0.0160  0.0139  0.0215 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I^2(%)  88.0966 84.9208 93.0443 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> H^2      8.4010  6.6317 14.3766 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### forest plot</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://wviechtb.github.io/metafor/reference/forest.html" class="external-link">forest</a></span><span class="op">(</span><span class="va">res</span>, header<span class="op">=</span><span class="cn">TRUE</span>, refline<span class="op">=</span><span class="fl">0.5</span>, xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.38</span>,<span class="fl">0.72</span><span class="op">)</span>, digits<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="dat.bartos2023-1.png" alt="" width="864" height="768"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### funnel plot</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://wviechtb.github.io/metafor/reference/funnel.html" class="external-link">funnel</a></span><span class="op">(</span><span class="va">res</span>, xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.45</span>,<span class="fl">0.6</span><span class="op">)</span>, ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">.02</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="dat.bartos2023-2.png" alt="" width="864" height="768"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### fit a random-effects model excluding those with same-side proportions larger than 0.53</span></span></span>
<span class="r-in"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span><span class="va">yi</span>, <span class="va">vi</span>, data<span class="op">=</span><span class="va">dat</span>, subset<span class="op">=</span><span class="va">yi</span><span class="op">&lt;=</span><span class="fl">0.53</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Random-Effects Model (k = 44; tau^2 estimator: REML)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau^2 (estimated amount of total heterogeneity): 0.0000 (SE = 0.0000)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau (square root of estimated tau^2 value):      0.0070</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I^2 (total heterogeneity / total variability):   60.08%</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> H^2 (total variability / sampling variability):  2.50</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Test for Heterogeneity:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Q(df = 43) = 113.3824, p-val &lt; .0001</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Model Results:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> estimate      se      zval    pval   ci.lb   ci.ub      </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.5060  0.0014  353.6383  &lt;.0001  0.5032  0.5088  *** </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ---</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">res</span>, type<span class="op">=</span><span class="st">"PL"</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        estimate   ci.lb   ci.ub </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau^2    0.0000  0.0000  0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau      0.0070  0.0070  0.0105 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I^2(%)  60.0772 60.0772 77.1134 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> H^2      2.5048  2.5048  4.3694 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### fit a binomial-normal model</span></span></span>
<span class="r-in"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.glmm.html" class="external-link">rma.glmm</a></span><span class="op">(</span>measure<span class="op">=</span><span class="st">"PLO"</span>, xi<span class="op">=</span><span class="va">same</span>, ni<span class="op">=</span><span class="va">flips</span>, data<span class="op">=</span><span class="va">dat</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Random-Effects Model (k = 48; tau^2 estimator: ML)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau^2 (estimated amount of total heterogeneity): 0.0039</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau (square root of estimated tau^2 value):      0.0626</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I^2 (total heterogeneity / total variability):   87.62%</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> H^2 (total variability / sampling variability):  8.08</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tests for Heterogeneity:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Wld(df = 47) = 263.9502, p-val &lt; .0001</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> LRT(df = 47) = 266.1506, p-val &lt; .0001</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Model Results:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> estimate      se    zval    pval   ci.lb   ci.ub      </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.0399  0.0099  4.0132  &lt;.0001  0.0204  0.0593  *** </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ---</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">res</span>, transf<span class="op">=</span><span class="va">plogis</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    pred  ci.lb  ci.ub  pi.lb  pi.ub </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5100 0.5051 0.5148 0.4789 0.5409 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### conduct a meta-analysis for the proportions of heads (to examine heads-tails bias)</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/escalc.html" class="external-link">escalc</a></span><span class="op">(</span>measure<span class="op">=</span><span class="st">"PR"</span>, xi<span class="op">=</span><span class="va">hdiff</span><span class="op">+</span><span class="va">hsame</span>, ni<span class="op">=</span><span class="va">flips</span>, data<span class="op">=</span><span class="va">dat</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.uni.html" class="external-link">rma</a></span><span class="op">(</span><span class="va">yi</span>, <span class="va">vi</span>, data<span class="op">=</span><span class="va">dat</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Random-Effects Model (k = 48; tau^2 estimator: REML)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau^2 (estimated amount of total heterogeneity): 0.0000 (SE = 0.0000)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau (square root of estimated tau^2 value):      0.0002</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I^2 (total heterogeneity / total variability):   0.12%</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> H^2 (total variability / sampling variability):  1.00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Test for Heterogeneity:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Q(df = 47) = 51.6720, p-val = 0.2963</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Model Results:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> estimate      se      zval    pval   ci.lb   ci.ub      </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   0.5001  0.0008  591.9090  &lt;.0001  0.4985  0.5018  *** </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ---</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">res</span>, type<span class="op">=</span><span class="st">"PL"</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        estimate  ci.lb  ci.ub </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau^2    0.0000 0.0000 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau      0.0002 0.0000 0.0002 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I^2(%)   0.1212 0.0000 0.1212 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> H^2      1.0012 1.0000 1.0012 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### restructure the dataset for a bivariate meta-analysis of same-side and heads proportions</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="va">dat.bartos2023</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="va">dat</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>, each<span class="op">=</span><span class="fl">2</span><span class="op">)</span>,<span class="op">]</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span></span>
<span class="r-in"><span><span class="va">dat</span><span class="op">$</span><span class="va">outcome</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"heads"</span>, <span class="st">"same"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/escalc.html" class="external-link">escalc</a></span><span class="op">(</span>measure<span class="op">=</span><span class="st">"PR"</span>, xi<span class="op">=</span><span class="va">hsame</span><span class="op">+</span><span class="va">hdiff</span>, ni<span class="op">=</span><span class="va">flips</span>, data<span class="op">=</span><span class="va">dat</span>, include<span class="op">=</span><span class="va">outcome</span><span class="op">==</span><span class="st">"heads"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/escalc.html" class="external-link">escalc</a></span><span class="op">(</span>measure<span class="op">=</span><span class="st">"PR"</span>, xi<span class="op">=</span><span class="va">hsame</span><span class="op">+</span><span class="va">tsame</span>, ni<span class="op">=</span><span class="va">flips</span>, data<span class="op">=</span><span class="va">dat</span>, include<span class="op">=</span><span class="va">outcome</span><span class="op">==</span><span class="st">"same"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">dat</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        person hsame hdiff tsame tdiff  same flips outcome     yi     vi </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 1     XiaoyiL   375   406   405   414   780  1600   heads 0.4881 0.0002 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 2     XiaoyiL   375   406   405   414   780  1600    same 0.4875 0.0002 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 3    JoyceYCP   588   586   538   588  1126  2300   heads 0.5104 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 4    JoyceYCP   588   586   538   588  1126  2300    same 0.4896 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 5   AndreeaSZ  1129  1134  1075  1139  2204  4477   heads 0.5055 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 6   AndreeaSZ  1129  1134  1075  1139  2204  4477    same 0.4923 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 7     KaleemU  3506  3642  3550  3626  7056 14324   heads 0.4990 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 8     KaleemU  3506  3642  3550  3626  7056 14324    same 0.4926 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 9    FelipeFV  2502  2531  2455  2527  4957 10015   heads 0.5025 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 10   FelipeFV  2502  2531  2455  2527  4957 10015    same 0.4950 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 11      ArneJ   995   982   942   981  1937  3900   heads 0.5069 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 12      ArneJ   995   982   942   981  1937  3900    same 0.4967 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 13      AmirS  3756  3775  3702  3779  7458 15012   heads 0.5017 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 14      AmirS  3756  3775  3702  3779  7458 15012    same 0.4968 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 15    ChrisGI  2546  2519  2425  2515  4971 10005   heads 0.5062 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 16    ChrisGI  2546  2519  2425  2515  4971 10005    same 0.4969 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 17  FrederikA  2564  2638  2655  2643  5219 10500   heads 0.4954 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 18  FrederikA  2564  2638  2655  2643  5219 10500    same 0.4970 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 19 FranziskaN  2634  2718  2734  2671  5368 10757   heads 0.4975 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 20 FranziskaN  2634  2718  2734  2671  5368 10757    same 0.4990 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 21   RietvanB   876   899   925   900  1801  3600   heads 0.4931 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 22   RietvanB   876   899   925   900  1801  3600    same 0.5003 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 23     JasonN  1692  1676  1660  1672  3352  6700   heads 0.5027 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 24     JasonN  1692  1676  1660  1672  3352  6700    same 0.5003 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 25   PierreYG  3825  3745  3681  3749  7506 15000   heads 0.5047 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 26   PierreYG  3825  3745  3681  3749  7506 15000    same 0.5004 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 27  KarolineH  1370  1369  1391  1370  2761  5500   heads 0.4980 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 28  KarolineH  1370  1369  1391  1370  2761  5500    same 0.5020 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 29    SjoerdT  1291  1247  1219  1243  2510  5000   heads 0.5076 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 30    SjoerdT  1291  1247  1219  1243  2510  5000    same 0.5020 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 31      SaraS  2615  2486  2407  2492  5022 10000   heads 0.5101 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 32      SaraS  2615  2486  2407  2492  5022 10000    same 0.5022 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 33   HenrikRG  4382  4264  4267  4269  8649 17182   heads 0.5032 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 34   HenrikRG  4382  4264  4267  4269  8649 17182    same 0.5034 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 35      IrmaT   188   173   165   175   353   701   heads 0.5150 0.0004 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 36      IrmaT   188   173   165   175   353   701    same 0.5036 0.0004 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 37 KatharinaK  1136  1088  1084  1092  2220  4400   heads 0.5055 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 38 KatharinaK  1136  1088  1084  1092  2220  4400    same 0.5045 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 39      JillR  1619  1601  1642  1601  3261  6463   heads 0.4982 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 40      JillR  1619  1601  1642  1601  3261  6463    same 0.5046 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 41 FrantisekB  5097  4979  5051  4973 10148 20100   heads 0.5013 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 42 FrantisekB  5097  4979  5051  4973 10148 20100    same 0.5049 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 43 IngeborgBR  2132  2126  2208  2130  4340  8596   heads 0.4953 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 44 IngeborgBR  2132  2126  2208  2130  4340  8596    same 0.5049 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 45  VincentLO  1143  1215  1332  1210  2475  4900   heads 0.4812 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 46  VincentLO  1143  1215  1332  1210  2475  4900    same 0.5051 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 47     EricJW  1012  1015  1059  1014  2071  4100   heads 0.4944 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 48     EricJW  1012  1015  1059  1014  2071  4100    same 0.5051 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 49     MalteZ  2831  2715  2728  2726  5559 11000   heads 0.5042 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 50     MalteZ  2831  2715  2728  2726  5559 11000    same 0.5054 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 51  TheresaEL   895   866   874   865  1769  3500   heads 0.5031 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 52  TheresaEL   895   866   874   865  1769  3500    same 0.5054 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 53     DavidV  3552  3933  4034  3480  7586 14999   heads 0.4990 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 54     DavidV  3552  3933  4034  3480  7586 14999    same 0.5058 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 55    AntonJZ  2587  2463  2482  2472  5069 10004   heads 0.5048 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 56    AntonJZ  2587  2463  2482  2472  5069 10004    same 0.5067 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 57     MagdaM  1244  1221  1266  1213  2510  4944   heads 0.4986 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 58     MagdaM  1244  1221  1266  1213  2510  4944    same 0.5077 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 59    ThomasB  1221  1233  1319  1227  2540  5000   heads 0.4908 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 60    ThomasB  1221  1233  1319  1227  2540  5000    same 0.5080 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 61     BohanF   580   544   538   538  1118  2200   heads 0.5109 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 62     BohanF   580   544   538   538  1118  2200    same 0.5082 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 63     JonasP  2546  2458  2534  2458  5080  9996   heads 0.5006 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 64     JonasP  2546  2458  2534  2458  5080  9996    same 0.5082 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 65    HannahA   704   739   821   736  1525  3000   heads 0.4810 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 66    HannahA   704   739   821   736  1525  3000    same 0.5083 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 67   AdrianKM   880   828   869   823  1749  3400   heads 0.5024 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 68   AdrianKM   880   828   869   823  1749  3400    same 0.5144 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 69    AaronBL  1937  1787  1878  1798  3815  7400   heads 0.5032 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 70    AaronBL  1937  1787  1878  1798  3815  7400    same 0.5155 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 71      KoenD  1622  1550  1687  1541  3309  6400   heads 0.4956 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 72      KoenD  1622  1550  1687  1541  3309  6400    same 0.5170 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 73 MichelleCD  1118  1037  1106  1039  2224  4300   heads 0.5012 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 74 MichelleCD  1118  1037  1106  1039  2224  4300    same 0.5172 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 75      RoyMM   971   942  1049   938  2020  3900   heads 0.4905 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 76      RoyMM   971   942  1049   938  2020  3900    same 0.5179 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 77      TingP   855   770   803   772  1658  3200   heads 0.5078 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 78      TingP   855   770   803   772  1658  3200    same 0.5181 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 79      MaraB   728   660   698   664  1426  2750   heads 0.5047 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 80      MaraB   728   660   698   664  1426  2750    same 0.5185 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 81      AdamF  2175  1996  2159  1998  4334  8328   heads 0.5008 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 82      AdamF  2175  1996  2159  1998  4334  8328    same 0.5204 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 83 AlexandraS  4556  4180  4524  4174  9080 17434   heads 0.5011 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 84 AlexandraS  4556  4180  4524  4174  9080 17434    same 0.5208 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 85   MadlenFH  1769  1699  1936  1694  3705  7098   heads 0.4886 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 86   MadlenFH  1769  1699  1936  1694  3705  7098    same 0.5220 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 87    DavidKL  3903  3552  3992  3553  7895 15000   heads 0.4970 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 88    DavidKL  3903  3552  3992  3553  7895 15000    same 0.5263 0.0000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 89 XiaochangZ   901   804   968   808  1869  3481   heads 0.4898 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 90 XiaochangZ   901   804   968   808  1869  3481    same 0.5369 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 91 FranziskaA   990   876  1065   869  2055  3800   heads 0.4911 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 92 FranziskaA   990   876  1065   869  2055  3800    same 0.5408 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 93       JanY   510   368   446   367   956  1691   heads 0.5192 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 94       JanY   510   368   446   367   956  1691    same 0.5653 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 95    TianqiP   780   557   902   561  1682  2800   heads 0.4775 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 96    TianqiP   780   557   902   561  1682  2800    same 0.6007 0.0001 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### construct the 2x2 variance-covariance matrix of the proportions within persons</span></span></span>
<span class="r-in"><span><span class="va">dat</span><span class="op">$</span><span class="va">cov</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">dat</span>, <span class="op">(</span><span class="va">hsame</span><span class="op">/</span><span class="va">flips</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">hsame</span><span class="op">/</span><span class="va">flips</span><span class="op">)</span> <span class="op">-</span> <span class="va">hsame</span><span class="op">/</span><span class="va">flips</span> <span class="op">*</span> <span class="va">tsame</span><span class="op">/</span><span class="va">flips</span> <span class="op">-</span></span></span>
<span class="r-in"><span>                      <span class="va">hsame</span><span class="op">/</span><span class="va">flips</span> <span class="op">*</span> <span class="va">hdiff</span><span class="op">/</span><span class="va">flips</span> <span class="op">-</span> <span class="va">hdiff</span><span class="op">/</span><span class="va">flips</span> <span class="op">*</span> <span class="va">tsame</span><span class="op">/</span><span class="va">flips</span><span class="op">)</span> <span class="op">/</span> <span class="va">flips</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">V</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/split.html" class="external-link">split</a></span><span class="op">(</span><span class="va">dat</span>, <span class="va">dat</span><span class="op">$</span><span class="va">person</span><span class="op">)</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">vi</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">x</span><span class="op">$</span><span class="va">cov</span>, <span class="va">x</span><span class="op">$</span><span class="va">vi</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>, nrow<span class="op">=</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### fit bivariate meta-analysis model</span></span></span>
<span class="r-in"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://wviechtb.github.io/metafor/reference/rma.mv.html" class="external-link">rma.mv</a></span><span class="op">(</span><span class="va">yi</span>, <span class="va">V</span>, mods <span class="op">=</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">outcome</span>, random <span class="op">=</span> <span class="op">~</span> <span class="va">outcome</span> <span class="op">|</span> <span class="va">person</span>, struct<span class="op">=</span><span class="st">"UN"</span>, data<span class="op">=</span><span class="va">dat</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Multivariate Meta-Analysis Model (k = 96; method: REML)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Variance Components:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> outer factor: person  (nlvls = 48)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> inner factor: outcome (nlvls = 2)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>             estim    sqrt  k.lvl  fixed  level </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau^2.1    0.0000  0.0036     48     no  heads </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> tau^2.2    0.0002  0.0151     48     no   same </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>        rho.heds  rho.same    heds  same </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> heads         1                 -    48 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> same    -0.3182         1      no     - </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Test for Residual Heterogeneity:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> QE(df = 94) = 306.8462, p-val &lt; .0001</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Test of Moderators (coefficients 1:2):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> QM(df = 2) = 320714.6985, p-val &lt; .0001</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Model Results:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>               estimate      se      zval    pval   ci.lb   ci.ub      </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> outcomeheads    0.5006  0.0010  486.8453  &lt;.0001  0.4986  0.5026  *** </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> outcomesame     0.5097  0.0024  211.1394  &lt;.0001  0.5049  0.5144  *** </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ---</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">### create plot with confidence ellipses ('ellipse' package must be installed)</span></span></span>
<span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dmurdoch/ellipse" class="external-link">ellipse</a></span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Attaching package: ‘ellipse’</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> The following object is masked from ‘package:graphics’:</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> </span>
<span class="r-msg co"><span class="r-pr">#&gt;</span>     pairs</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="cn">NA</span>, xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.45</span>,<span class="fl">0.62</span><span class="op">)</span>, ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.45</span>,<span class="fl">0.62</span><span class="op">)</span>, bty<span class="op">=</span><span class="st">"l"</span>, xlab<span class="op">=</span><span class="st">"Pr(heads)"</span>, ylab<span class="op">=</span><span class="st">"Pr(same)"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>h<span class="op">=</span><span class="fl">0.5</span>, lty<span class="op">=</span><span class="st">"dotted"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v<span class="op">=</span><span class="fl">0.5</span>, lty<span class="op">=</span><span class="st">"dotted"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># add confidence ellipses for persons</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/invisible.html" class="external-link">invisible</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/tapply.html" class="external-link">tapply</a></span><span class="op">(</span><span class="va">dat</span>, <span class="va">dat</span><span class="op">$</span><span class="va">person</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>   <span class="va">xy</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dmurdoch.github.io/ellipse/reference/ellipse.html" class="external-link">ellipse</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">vi</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="va">x</span><span class="op">$</span><span class="va">cov</span>,<span class="va">x</span><span class="op">$</span><span class="va">vi</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>, nrow<span class="op">=</span><span class="fl">2</span><span class="op">)</span>, centre<span class="op">=</span><span class="va">x</span><span class="op">$</span><span class="va">yi</span>, level<span class="op">=</span><span class="fl">0.95</span><span class="op">)</span></span></span>
<span class="r-in"><span>   <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">xy</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,<span class="va">xy</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, col<span class="op">=</span><span class="st">"gray80"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># add the points</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/invisible.html" class="external-link">invisible</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/tapply.html" class="external-link">tapply</a></span><span class="op">(</span><span class="va">dat</span>, <span class="va">dat</span><span class="op">$</span><span class="va">person</span>, \<span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">yi</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">x</span><span class="op">$</span><span class="va">yi</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, pch<span class="op">=</span><span class="fl">21</span>, bg<span class="op">=</span><span class="st">"gray80"</span>, cex<span class="op">=</span><span class="fl">1.5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># add the 95% PI ellipsis based on the model</span></span></span>
<span class="r-in"><span><span class="va">xy</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dmurdoch.github.io/ellipse/reference/ellipse.html" class="external-link">ellipse</a></span><span class="op">(</span><span class="va">res</span><span class="op">$</span><span class="va">G</span>, centre<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span>, level<span class="op">=</span><span class="fl">0.95</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">xy</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,<span class="va">xy</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, col<span class="op">=</span><span class="st">"gray30"</span>, lwd<span class="op">=</span><span class="fl">3</span>, lty<span class="op">=</span><span class="st">"dotted"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># add the 95% CI ellipsis based on the model</span></span></span>
<span class="r-in"><span><span class="va">xy</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dmurdoch.github.io/ellipse/reference/ellipse.html" class="external-link">ellipse</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html" class="external-link">vcov</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span>, centre<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span>, level<span class="op">=</span><span class="fl">0.95</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">xy</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,<span class="va">xy</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, col<span class="op">=</span><span class="st">"gray30"</span>, lwd<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># add the point for the pooled effects</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, pch<span class="op">=</span><span class="fl">21</span>, bg<span class="op">=</span><span class="st">"gray40"</span>, cex<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="dat.bartos2023-3.png" alt="" width="864" height="768"></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Thomas White, Daniel Noble, Alistair Senior, W. Kyle Hamilton, Wolfgang Viechtbauer.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
  <p class="preferably">Using <a href="https://preferably.amirmasoudabdol.name/?source=footer" class="external-link">preferably</a> template.</p>
</div>

      </footer></div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    appId: 'B3DHC2OOU8',
    
    apiKey: '8c74dd1e0cd05800bf9f222777e07625',
    indexName: 'wviechtb-metadat',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script></body></html>

